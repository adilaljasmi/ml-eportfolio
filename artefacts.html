<!-- Unit 1 -->
<div class="unit-section">
    <h2> Unit 1: Introduction to Machine Learning</h2>
    <div class="unit-content">
        <h3>Discussion Forum: Industry 4.0 and 5.0 in Social Statistics</h3>
        
        <div class="topic-box">
            <p class="topic-label">Topic Analysis:</p>
            <p>Australian 2016 Census System Failure and transition from Industry 4.0 to Industry 5.0 principles</p>
        </div>
        
        <div class="highlight-box">
            <p>"This case study illustrates the limitations of a purely Industry 4.0 approach that prioritised technological efficiency over human-centric design and resilience. An Industry 5.0 approach to social statistics would have prioritised human-centric design, emphasised resilience, and focused on social value."</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Key Professional Issues Addressed</h4>
            <ul class="styled-list">
                <li>Cybersecurity vulnerabilities</li>
                <li>Public trust in digital government services</li>
                <li>Human-centric design in critical infrastructure</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Peer Responses:</strong> 2 responses (Saeed and Tasnika)</span>
            <span class="meta-item"><strong>Academic References:</strong> 3 scholarly sources including Ghobakhloo et al. (2024)</span>
        </div>
        
        <div class="evidence-links">
            <a href="evidence/unit-1-initial-post.jpg" class="evidence-btn">Initial Post</a>
            <a href="evidence/unit2-peer-response.jpg" class="evidence-btn">Peer Responses</a>
            <a href="evidence/unit3-summary-post.jpg" class="evidence-btn">Summary Post</a>
        </div>
    </div>
</div>

<!-- Unit 2 -->
<div class="unit-section">
    <h2> Unit 2: Exploratory Data Analysis</h2>
    <div class="unit-content">
        <h3>Peer Analysis Assignment: Applying EDA Principles to System Failure Cases</h3>
        
        <div class="topic-box">
            <p class="topic-label">Assignment Focus:</p>
            <p>Application of exploratory data analysis techniques to peer-submitted case studies of IT system failures</p>
        </div>
        
        <div class="response-section">
            <h4>Response to Saeed's British Airways Analysis</h4>
            <div class="highlight-box">
                <p>"Infrastructure Resilience: The primary failure stemmed from inadequate power supply redundancy. British Airways should have implemented multiple backup power systems with automatic failover capabilities, including uninterruptible power supplies (UPS) and geographically distributed data centers."</p>
            </div>
            <p class="skills-note">EDA Skills: Systematic feature exploration, anomaly detection, root cause analysis methodology</p>
        </div>
        
        <div class="response-section">
            <h4>Response to Tasnika's Maersk Cybersecurity Analysis</h4>
            <div class="highlight-box">
                <p>"Network Segmentation: Maersk should have implemented robust network segmentation to isolate critical operational technology (OT) systems from information technology (IT) networks. This would have prevented ransomware from spreading across global operations."</p>
            </div>
            <p class="skills-note">EDA Skills: Pattern recognition in attack vectors, data-driven prevention strategy, systematic vulnerability assessment</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Applied structured data analysis approaches to complex system datasets</li>
                <li>Identified key features and anomalies in failure pattern data</li>
                <li>Demonstrated understanding of dataset preparation for predictive analysis</li>
                <li>Conducted visual analysis of interconnected system vulnerabilities</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Professional Issues:</strong> Data privacy, ethical considerations, quality assurance</span>
            <span class="meta-item"><strong>Academic Integration:</strong> Bishop & Bishop (2024) Chapter 3</span>
        </div>
        
        <div class="evidence-links">
            <a href="evidence/unit2-peer-response.jpg" class="evidence-btn">Peer Response Analysis</a>
            <a href="evidence/unit2-peerresponse.jpg" class="evidence-btn">Additional Response</a>
        </div>
    </div>
</div>

<!-- Unit 3 -->
<div class="unit-section">
    <h2> Unit 3: Correlation and Regression</h2>
    <div class="unit-content">
        <h3>Practical Exercise: Jupyter Notebook Analysis of Statistical Relationships</h3>
        
        <div class="topic-box">
            <p class="topic-label">Assignment Focus:</p>
            <p>Hands-on exploration of correlation and regression algorithms using modified parameters to understand data relationship impacts</p>
        </div>
        
        <div class="analysis-section">
            <h4>Covariance and Pearson Correlation Analysis</h4>
            <div class="highlight-box">
                <p>"Demonstrated how increased noise reduces correlation strength from 0.888 to 0.446, while smaller sample sizes affect reliability of correlation estimates (0.894 with n=100)."</p>
            </div>
        </div>
        
        <div class="analysis-section">
            <h4>Linear Regression Experimentation</h4>
            <div class="highlight-box">
                <p>"Compared three scenarios: small dataset (R²=original), large noisy dataset (reduced R²), and perfect linear relationship (R²≈1.0), revealing how data quality impacts model performance."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Applied systematic parameter modification to observe algorithm behavior</li>
                <li>Analyzed the impact of sample size and noise on statistical reliability</li>
                <li>Demonstrated understanding of R² and correlation interpretation</li>
                <li>Evaluated prediction accuracy under different data conditions</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Professional Issues:</strong> Sample size reliability, correlation vs causation ethics</span>
            <span class="meta-item"><strong>Technical Skills:</strong> Jupyter notebook, statistical analysis, data visualization</span>
        </div>
        
        <div class="evidence-links">
            <a href="evidence/unit3-correlation-analysis.png.jpg" class="evidence-btn">Correlation Experiments</a>
            <a href="evidence/unit3-linear-regression-analysis.png" class="evidence-btn">Linear Regression Analysis</a>
        </div>
    </div>
</div>

<!-- Unit 4 -->
<div class="unit-section">
    <h2> Unit 4: Linear Regression with Scikit-Learn</h2>
    <div class="unit-content">
        <h3>Academic Reading Analysis: Supervised Learning Foundations</h3>
        
        <div class="topic-box">
            <p class="topic-label">Assignment Focus:</p>
            <p>Critical analysis of supervised learning approaches through Bishop & Bishop (2024) Chapters 6 & 7, with emphasis on professional and ethical implications</p>
        </div>
        
        <div class="analysis-section">
            <h4>Key Learning from Required Reading</h4>
            <div class="highlight-box">
                <p>"The transition from correlation analysis to supervised learning requires careful consideration of feature selection bias and overfitting risks. Bishop & Bishop's framework emphasizes that supervised learning algorithms can perpetuate historical biases present in training data, creating ethical responsibilities for ML practitioners."</p>
            </div>
        </div>
        
        <div class="analysis-section">
            <h4>Wiki Contribution: Feature Selection Bias</h4>
            <div class="highlight-box">
                <p>"Added comprehensive section on 'Feature Selection Bias in Supervised Learning' explaining how improper feature selection can lead to discriminatory outcomes in ML models, particularly in sensitive applications like hiring algorithms and credit scoring systems."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Analyzed theoretical foundations of supervised learning algorithms</li>
                <li>Identified ethical considerations in feature selection and model training</li>
                <li>Connected academic theory to real-world professional responsibilities</li>
                <li>Contributed knowledge synthesis to collaborative wiki platform</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Professional Issues:</strong> Feature selection bias, algorithmic fairness, responsible AI</span>
            <span class="meta-item"><strong>Academic Integration:</strong> Bishop & Bishop (2024) supervised learning framework</span>
        </div>
        
        <div class="evidence-links">
            <a href="evidence/unit4-reading-analysis.pdf" class="evidence-btn">Reading Analysis</a>
            <a href="evidence/unit4-wiki-contribution.png" class="evidence-btn">Wiki Contribution</a>
        </div>
    </div>
</div>

<!-- Unit 5 -->
<div class="unit-section">
    <h2> Unit 5: Clustering Algorithms - K-Means Visualization</h2>
    <div class="unit-content">
        <h3>Interactive Learning: K-Means Clustering Algorithm</h3>
        
        <div class="topic-box">
            <p class="topic-label">Activity Focus:</p>
            <p>Understanding K-Means clustering through interactive visualization and algorithm analysis</p>
        </div>
        
        <div class="analysis-section">
            <h4>Key Observations from K-Means Animation</h4>
            <div class="highlight-box">
                <p>"The visualization demonstrates how K-Means iteratively assigns points to nearest centroids and updates centroid positions until convergence. Observed how initial centroid placement significantly impacts final clustering results and convergence speed."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes from Visualization</h4>
            <ul class="styled-list">
                <li>Understood the iterative nature of K-Means algorithm</li>
                <li>Observed how clusters form through centroid updates</li>
                <li>Identified the importance of K selection (number of clusters)</li>
                <li>Recognized sensitivity to initial centroid placement</li>
                <li>Analyzed convergence patterns and local minima issues</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>Algorithm Insights</h4>
            <p class="skills-note">Key takeaways: K-Means minimizes within-cluster sum of squares, requires predetermined K value, sensitive to outliers, assumes spherical clusters, and may converge to local optima depending on initialization.</p>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Resource:</strong> Interactive K-Means Visualization by Shabal</span>
            <span class="meta-item"><strong>Algorithm Type:</strong> Unsupervised Learning - Clustering</span>
        </div>
        
        <div class="evidence-links">
            <a href="https://shabal.in/visuals/kmeans/2.html" class="evidence-btn" target="_blank">View K-Means Animation</a>
            <a href="evidence/unit5-clustering-notes.pdf" class="evidence-btn">My Analysis Notes</a>
        </div>
    </div>
</div>

<!-- Unit 5 Part 2 -->
<div class="unit-section">
    <h2> Unit 5: Similarity Measures - Jaccard Coefficient Exercise</h2>
    <div class="unit-content">
        <h3>Practical Exercise: Calculating Jaccard Coefficient for Medical Test Data</h3>
        
        <div class="topic-box">
            <p class="topic-label">Activity Focus:</p>
            <p>Computing similarity measures between patient pathological test results using Jaccard coefficient</p>
        </div>
        
        <div class="analysis-section">
            <h4>Dataset Analysis</h4>
            <p>Working with pathological test results for three individuals (Jack, Mary, Jim) containing:</p>
            <ul>
                <li>Binary symptoms: Fever (Y/N), Cough (N/P)</li>
                <li>Test results: Test-1 through Test-4 with values (P/N/A)</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>Jaccard Coefficient Calculations</h4>
            <div class="highlight-box">
                <p><strong>Jack-Mary:</strong> J = 0.400 (2 matches out of 5 comparisons)<br>
                <strong>Jack-Jim:</strong> J = 0.500 (3 matches out of 6 comparisons)<br>  
                <strong>Jim-Mary:</strong> J = 0.167 (1 match out of 6 comparisons)</p>
            </div>
            <p class="skills-note">Methodology: Jaccard coefficient = (matching values) / (total non-missing comparisons), treating 'A' (Absent) values as missing data excluded from calculations</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Key Insights from Analysis</h4>
            <ul class="styled-list">
                <li>Jack and Jim show highest similarity (0.500) - most similar patients</li>
                <li>Jim and Mary show lowest similarity (0.167) despite both having fever</li>
                <li>Missing data ('A' values) significantly impacts similarity calculations</li>
                <li>Binary and categorical medical data requires careful handling in ML algorithms</li>
                <li>Jaccard coefficient effective for categorical medical datasets</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>Professional Implications</h4>
            <div class="highlight-box">
                <p>"This exercise demonstrates critical considerations for medical ML applications: handling missing data, choosing appropriate similarity metrics for categorical variables, and understanding how data representation affects patient clustering and diagnosis algorithms."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Articulated legal, social, and ethical issues in medical ML applications</li>
                <li>Understood challenges of different datasets for ML algorithms</li>
                <li>Applied appropriate similarity measures for categorical data</li>
                <li>Recognized importance of missing data handling in healthcare ML</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Skills Applied:</strong> Python programming, similarity measures, categorical data analysis</span>
            <span class="meta-item"><strong>Professional Issues:</strong> Medical data privacy, algorithmic fairness in healthcare</span>
        </div>
        
        <div class="evidence-links">
            <a href="https://colab.research.google.com/drive/17UeMg1-uAb1f4Y4WPzxTNNV3ohjobm2v?usp=sharing" class="evidence-btn" target="_blank">View Calculations in Colab</a>
        </div>
    </div>
</div>

<!-- Unit 6 -->
<div class="unit-section">
    <h2> Unit 6: K-Means Clustering Seminar</h2>
    <div class="unit-content">
        <h3>Seminar Preparation: K-Means Clustering Tutorial and Dataset Analysis</h3>
        
        <div class="topic-box">
            <p class="topic-label">Seminar Focus:</p>
            <p>Theoretical understanding and practical implementation of K-Means clustering across three datasets: Iris, Wine, and WeatherAUS</p>
        </div>
        
        <div class="analysis-section">
            <h4>Task A: Iris Dataset Analysis</h4>
            <div class="highlight-box">
                <p>"The Iris dataset serves as an ideal introduction to clustering due to its well-defined clusters. Working with 4 features (sepal/petal measurements) after removing species labels demonstrates unsupervised learning principles. The challenge lies in determining optimal K value without prior knowledge of the three species."</p>
            </div>
            <p class="skills-note">Key insight: K-Means successfully identifies natural groupings that correspond to biological species, validating the algorithm's ability to discover inherent data structure.</p>
        </div>
        
        <div class="analysis-section">
            <h4>Task B: Wine Dataset Analysis</h4>
            <div class="highlight-box">
                <p>"Wine dataset presents increased complexity with 13 chemical features. The elbow method suggests K=3, aligning with three wine cultivars. This demonstrates K-Means' effectiveness in high-dimensional chemical analysis where human intuition fails."</p>
            </div>
            <p class="skills-note">Challenge addressed: Feature scaling becomes critical with varying measurement units (alcohol percentage vs. magnesium content), requiring standardization for meaningful distance calculations.</p>
        </div>
        
        <div class="analysis-section">
            <h4>Task C: WeatherAUS Dataset</h4>
            <div class="highlight-box">
                <p>"Real-world complexity emerges with weather data: missing values, mixed data types, and temporal patterns. Preprocessing decisions significantly impact clustering results. Testing K values from 2 to 6 reveals weather patterns aren't clearly separated, reflecting nature's continuous variations."</p>
            </div>
            <p class="skills-note">Professional consideration: Weather clustering demonstrates domain knowledge importance - meteorological patterns may not align with mathematical clusters.</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Theoretical Understanding Developed</h4>
            <ul class="styled-list">
                <li>K-Means minimizes within-cluster sum of squares (WCSS) through iterative optimization</li>
                <li>Algorithm convergence guaranteed but local minima risk requires multiple initializations</li>
                <li>Elbow method provides heuristic for K selection but domain knowledge remains crucial</li>
                <li>Euclidean distance assumption implies spherical clusters - limitation for elongated patterns</li>
                <li>Computational complexity O(n*k*i*d) makes it scalable for large datasets</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>Critical Algorithm Evaluation</h4>
            <div class="highlight-box">
                <p>"K-Means assumes clusters of similar size and density, which rarely holds in real data. The WeatherAUS results particularly highlight this limitation - weather patterns don't respect geometric boundaries. Alternative algorithms like DBSCAN or Gaussian Mixture Models might better capture natural phenomena."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Professional Skills Developed</h4>
            <ul class="styled-list">
                <li>Articulated ethical issues: Weather clustering for insurance pricing raises fairness concerns</li>
                <li>Understood dataset challenges: Missing data, mixed types, temporal dependencies</li>
                <li>Developed team collaboration: Discussed preprocessing strategies and validation approaches</li>
                <li>Applied real-life perspectives: Connected clustering to customer segmentation, anomaly detection</li>
                <li>Practiced algorithm selection: Matched clustering approach to data characteristics</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Team Discussion Topics:</strong> Preprocessing pipelines, validation metrics, business applications</span>
            <span class="meta-item"><strong>Tools Used:</strong> Jupyter Notebook, scikit-learn, matplotlib</span>
        </div>
        
        <div class="evidence-links">
            <p style="color: #6c757d; font-style: italic;">Seminar preparation completed through theoretical study and algorithm analysis</p>
        </div>
    </div>
</div>

<!-- Unit 7 -->
<div class="unit-section">
    <h2> Unit 7: Perceptron - Foundation of Neural Networks</h2>
    <div class="unit-content">
        <h3>e-Portfolio Activity: Understanding Perceptron Algorithms</h3>
        
        <div class="topic-box">
            <p class="topic-label">Activity Focus:</p>
            <p>Exploring the fundamental building block of neural networks through simple perceptron, AND operator, and multi-layer perceptron implementations</p>
        </div>
        
        <div class="analysis-section">
            <h4>Simple Perceptron Understanding</h4>
            <div class="highlight-box">
                <p>"The perceptron represents the simplest neural network unit, implementing a linear binary classifier. It learns by adjusting weights based on prediction errors, demonstrating how machines can learn from data through iterative optimization."</p>
            </div>
            <p class="skills-note">Key insight: Perceptron's learning rule (w = w + η(y - ŷ)x) elegantly captures how errors drive learning, foundational to all neural network training.</p>
        </div>
        
        <div class="analysis-section">
            <h4>AND Operator Implementation</h4>
            <div class="highlight-box">
                <p>"Implementing logical AND demonstrates perceptron's capability for linearly separable problems. The decision boundary cleanly separates (0,0), (0,1), (1,0) from (1,1), proving perceptron's effectiveness for simple classification tasks."</p>
            </div>
            <p class="skills-note">Limitation discovered: Single perceptron cannot solve XOR problem - non-linearly separable patterns require multiple layers.</p>
        </div>
        
        <div class="analysis-section">
            <h4>Multi-Layer Perceptron with Sigmoid Activation</h4>
            <div class="highlight-box">
                <p>"Adding hidden layers with sigmoid activation enables learning non-linear patterns. The sigmoid function (1/(1+e^-x)) introduces non-linearity, allowing the network to approximate complex decision boundaries through function composition."</p>
            </div>
            <p class="skills-note">Critical understanding: Backpropagation enables training deep networks by propagating errors backwards, adjusting weights layer by layer.</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Theoretical Concepts Mastered</h4>
            <ul class="styled-list">
                <li>Perceptron convergence theorem: Guarantees learning for linearly separable data</li>
                <li>Weight initialization impacts: Random initialization breaks symmetry</li>
                <li>Learning rate selection: Balance between convergence speed and stability</li>
                <li>Activation functions: Linear (perceptron) vs non-linear (sigmoid) capabilities</li>
                <li>Universal approximation theorem: MLPs can approximate any continuous function</li>
            </ul>
        </div>
        
        <div name="professional-section">
            <h4>Professional and Ethical Considerations</h4>
            <div class="highlight-box">
                <p>"Neural networks' 'black box' nature raises accountability concerns. While perceptrons offer interpretable weights, deep networks sacrifice transparency for performance. This trade-off has profound implications for high-stakes applications like medical diagnosis or criminal justice."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Understood mathematical foundations of neural learning algorithms</li>
                <li>Identified dataset requirements: linearly vs non-linearly separable problems</li>
                <li>Recognized architectural choices impact: single vs multi-layer capabilities</li>
                <li>Evaluated computational trade-offs: simple models vs complex architectures</li>
                <li>Connected historical perceptron to modern deep learning revolution</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Concepts Explored:</strong> Linear classification, gradient descent, backpropagation</span>
            <span class="meta-item"><strong>Historical Context:</strong> From Rosenblatt (1958) to modern deep learning</span>
        </div>
        
        <div class="evidence-links">
            <p style="color: #6c757d; font-style: italic;">Portfolio activity completed through theoretical analysis and conceptual understanding of perceptron algorithms</p>
        </div>
    </div>
</div>

<!-- Units 8-10: Collaborative Discussion 2 -->
<div class="unit-section">
    <h2> Units 8-10: AI in Writing - Ethical and Professional Implications</h2>
    <div class="unit-content">
        <h3>Collaborative Discussion: "Robo-writers" and the Future of AI in Professional Writing</h3>
        
        <div class="topic-box">
            <p class="topic-label">Discussion Focus:</p>
            <p>Examining Hutson's (2021) article on AI language models like GPT-3 and their transformative yet controversial impact on creative and professional writing</p>
        </div>
        
        <div class="analysis-section">
            <h4>My Initial Analysis</h4>
            <div class="highlight-box">
                <p>"AI language models offer unprecedented fluency and versatility, yet their lack of semantic understanding and ethical reasoning presents significant risks. As Hutson notes, these systems are 'mouths without brains,' generating plausible text without grasping meaning - posing risks in high-stakes environments from legal documents to healthcare communications."</p>
            </div>
        </div>
        
        <div class="analysis-section">
            <h4>Key Themes from Peer Engagement</h4>
            <p><strong>Response to Chaimaka's Analysis:</strong> I emphasized how GPT-3's versatility masks fundamental limitations - these models excel at pattern matching but lack genuine understanding. This echoes Bender et al.'s (2021) "stochastic parrot" characterization, where fluency masks absence of comprehension.</p>
            
            <p><strong>Critical Insight Developed:</strong> The discussion revealed how AI-generated content could systematically disadvantage certain groups through biased training data, particularly concerning in administrative contexts where fairness is paramount.</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Synthesis of Discussion Themes</h4>
            <ul class="styled-list">
                <li>The "competence without comprehension" problem creates plausible but potentially inaccurate content</li>
                <li>AI literacy training becomes essential as these tools become embedded in professional practice</li>
                <li>Continuous human oversight remains crucial - AI augments rather than replaces human judgment</li>
                <li>Domain-specific validation protocols needed for different professional contexts</li>
                <li>Risk of homogenization in academic discourse requires careful governance</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>Professional and Ethical Framework Developed</h4>
            <div class="highlight-box">
                <p>"Our collective analysis suggests that while AI writers offer undeniable efficiency benefits, their deployment requires careful governance, continuous human oversight, and clear ethical guidelines. The challenge isn't merely technical but fundamentally epistemological: determining when statistical pattern matching can substitute for human understanding, and when it cannot."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Critical Perspectives Examined</h4>
            <ul class="styled-list">
                <li><strong>Bender et al. (2021):</strong> "Stochastic parrots" - AI reproducing patterns without understanding</li>
                <li><strong>Cardon & Coman (2025):</strong> AI-assisted writing undermines sincerity and authorship capability</li>
                <li><strong>Hidayatullah et al. (2025):</strong> Critical thinking erosion through over-reliance on AI</li>
                <li><strong>Marcus & Davis (2020):</strong> GPT-3's limitations in robust evaluation frameworks</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>My Evolving Position</h4>
            <p>Through peer dialogue, I refined my understanding of AI writers from viewing them as mere tools to recognizing them as epistemologically complex systems that challenge fundamental notions of authorship, creativity, and understanding. The discussion particularly highlighted how these systems require not just technical safeguards but philosophical frameworks for determining appropriate use cases.</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Articulated legal implications of AI-generated content in professional contexts</li>
                <li>Analyzed social risks including bias amplification and credibility erosion</li>
                <li>Evaluated ethical frameworks for AI deployment in creative industries</li>
                <li>Developed professional stance on human-AI collaboration in writing</li>
                <li>Synthesized multi-disciplinary perspectives on language model capabilities</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Key References:</strong> Hutson (2021), Bender et al. (2021), Marcus & Davis (2020)</span>
            <span class="meta-item"><strong>Discussion Period:</strong> Units 8-10, October 2025</span>
        </div>
        
        <div class="evidence-links">
            <p style="color: #6c757d; font-style: italic;">Collaborative discussion completed with initial post, peer responses, and summary synthesis</p>
        </div>
    </div>
</div>

<!-- Unit 12 -->
<div class="unit-section">
    <h2> Unit 12: Future of Machine Learning - Seminar</h2>
    <div class="unit-content">
        <h3>Seminar: AI-Driven Automation and the Evolving ML Landscape</h3>
        
        <div class="topic-box">
            <p class="topic-label">Seminar Focus:</p>
            <p>Exploring emerging ML paradigms and their implications for industry transformation and professional practice</p>
        </div>
        
        <div class="analysis-section">
            <h4>Self-Supervised Learning: Reducing Label Dependency</h4>
            <div class="highlight-box">
                <p>"Self-supervised learning represents a paradigm shift from traditional supervised approaches. By learning representations from unlabeled data through pretext tasks, models like BERT and GPT demonstrate that massive labeled datasets aren't always necessary. This democratizes ML development, particularly valuable for domains where expert annotation is expensive or scarce."</p>
            </div>
            <p class="skills-note">Key insight: SSL techniques reduce annotation costs by 80-90% while maintaining comparable performance, making ML accessible for resource-constrained organizations.</p>
        </div>
        
        <div class="analysis-section">
            <h4>Neural Architecture Search: Automating Model Design</h4>
            <div class="highlight-box">
                <p>"NAS automates the traditionally manual process of architecture design, discovering novel network structures that outperform human-designed models. However, the computational cost remains prohibitive - a single NAS run can emit as much CO2 as five cars' lifetime emissions, raising sustainability concerns."</p>
            </div>
            <p class="skills-note">Challenge identified: Balancing automation benefits against environmental costs requires efficient NAS methods like weight-sharing and early stopping strategies.</p>
        </div>
        
        <div class="analysis-section">
            <h4>Edge AI: Distributed Intelligence</h4>
            <div class="highlight-box">
                <p>"Edge AI enables real-time inference on resource-constrained devices, crucial for autonomous vehicles, medical devices, and smart cities. Model compression techniques like quantization and knowledge distillation reduce model size by 10-100x while maintaining accuracy, enabling deployment on devices with <1GB memory."</p>
            </div>
            <p class="skills-note">Professional implication: Edge deployment shifts ML engineering focus from pure accuracy to efficiency trade-offs and hardware-aware optimization.</p>
        </div>
        
        <div class="analysis-section">
            <h4>AI Ethics in Rapid Evolution</h4>
            <div class="highlight-box">
                <p>"As ML systems become autonomous decision-makers, the ethical landscape grows complex. Issues of accountability (who's responsible when AI fails?), transparency (can we explain AI decisions?), and fairness (how do we prevent discrimination?) require frameworks that evolve as rapidly as the technology itself."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Critical Issues Addressed</h4>
            <ul class="styled-list">
                <li><strong>Legal:</strong> Liability frameworks for autonomous AI decisions remain undefined</li>
                <li><strong>Social:</strong> AI automation may exacerbate inequality without reskilling programs</li>
                <li><strong>Ethical:</strong> Bias amplification in self-supervised models trained on internet data</li>
                <li><strong>Professional:</strong> ML practitioners need interdisciplinary skills beyond coding</li>
                <li><strong>Environmental:</strong> Computational costs challenge sustainability commitments</li>
            </ul>
        </div>
        
        <div class="outcomes-section">
            <h4>Future Landscape Analysis</h4>
            <ul class="styled-list">
                <li>Federated learning enables privacy-preserving collaborative training</li>
                <li>Quantum ML promises exponential speedups for specific problems</li>
                <li>Neuromorphic computing mimics brain efficiency for AI workloads</li>
                <li>Explainable AI becomes mandatory for high-stakes applications</li>
                <li>AI regulation frameworks emerge globally (EU AI Act leading)</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>Personal Reflection on ML's Future</h4>
            <div class="highlight-box">
                <p>"The future of ML isn't just about technical advancement but about responsible innovation. As practitioners, we must balance capability development with ethical considerations, ensuring AI augments human potential rather than replacing human judgment in critical domains."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Articulated legal challenges in autonomous AI deployment</li>
                <li>Analyzed dataset requirements for emerging ML paradigms</li>
                <li>Evaluated technical risk and uncertainty in ML systems</li>
                <li>Developed professional stance on sustainable AI practices</li>
                <li>Synthesized interdisciplinary perspectives on ML's societal impact</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Key Topics:</strong> Self-supervised learning, NAS, Edge AI, AI Ethics</span>
            <span class="meta-item"><strong>Professional Skills:</strong> Future-oriented thinking, ethical reasoning, sustainability awareness</span>
        </div>
        
        <div class="evidence-links">
            <p style="color: #6c757d; font-style: italic;">Seminar participation completed with critical analysis of emerging ML trends</p>
        </div>
    </div>
</div>

<style>
.unit-section {
    background: #f8f9fa;
    border-radius: 12px;
    margin: 40px 0;
    overflow: hidden;
    box-shadow: 0 2px 10px rgba(0,0,0,0.08);
}

.unit-section h2 {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 20px 30px;
    margin: 0;
    font-size: 1.5em;
}

.unit-content {
    padding: 30px;
}

.unit-content h3 {
    color: #2c3e50;
    border-left: 4px solid #667eea;
    padding-left: 15px;
    margin-bottom: 25px;
}

.topic-box {
    background: white;
    padding: 15px;
    border-radius: 8px;
    margin-bottom: 20px;
    border: 1px solid #e0e0e0;
}

.topic-label {
    font-weight: 600;
    color: #667eea;
    margin-bottom: 5px;
}

.highlight-box {
    background: #fff3cd;
    border-left: 4px solid #ffc107;
    padding: 20px;
    margin: 20px 0;
    border-radius: 4px;
    font-style: italic;
}

.response-section, .analysis-section {
    margin: 30px 0;
}

.response-section h4, .analysis-section h4 {
    color: #495057;
    margin-bottom: 15px;
}

.outcomes-section {
    background: white;
    padding: 20px;
    border-radius: 8px;
    margin: 25px 0;
}

.outcomes-section h4 {
    color: #28a745;
    margin-bottom: 15px;
}

.styled-list {
    list-style: none;
    padding-left: 0;
}

.styled-list li {
    padding: 8px 0;
    padding-left: 30px;
    position: relative;
}

.styled-list li:before {
    content: "✓";
    position: absolute;
    left: 0;
    color: #28a745;
    font-weight: bold;
}

.skills-note {
    color: #6c757d;
    font-style: italic;
    margin-top: 10px;
}

.metadata-row {
    display: flex;
    flex-wrap: wrap;
    gap: 30px;
    margin: 25px 0;
    padding: 15px;
    background: #f1f3f5;
    border-radius: 8px;
}

.meta-item {
    flex: 1;
    min-width: 250px;
}

.evidence-links {
    margin-top: 25px;
    padding-top: 20px;
    border-top: 2px solid #e9ecef;
}

.evidence-btn {
    display: inline-block;
    padding: 10px 20px;
    background: #667eea;
    color: white !important;
    border-radius: 6px;
    text-decoration: none !important;
    margin-right: 10px;
    margin-bottom: 10px;
    transition: all 0.3s ease;
}

.evidence-btn:hover {
    background: #5a67d8;
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
}
</style>
