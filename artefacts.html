<!-- Unit 1 -->
<div class="unit-section">
    <h2>üìö Unit 1: Introduction to Machine Learning</h2>
    <div class="unit-content">
        <h3>Discussion Forum: Industry 4.0 and 5.0 in Social Statistics</h3>
        
        <div class="topic-box">
            <p class="topic-label">Topic Analysis:</p>
            <p>Australian 2016 Census System Failure and transition from Industry 4.0 to Industry 5.0 principles</p>
        </div>
        
        <div class="highlight-box">
            <p>"This case study illustrates the limitations of a purely Industry 4.0 approach that prioritised technological efficiency over human-centric design and resilience. An Industry 5.0 approach to social statistics would have prioritised human-centric design, emphasised resilience, and focused on social value."</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Key Professional Issues Addressed</h4>
            <ul class="styled-list">
                <li>Cybersecurity vulnerabilities</li>
                <li>Public trust in digital government services</li>
                <li>Human-centric design in critical infrastructure</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Peer Responses:</strong> 2 responses (Saeed and Tasnika)</span>
            <span class="meta-item"><strong>Academic References:</strong> 3 scholarly sources including Ghobakhloo et al. (2024)</span>
        </div>
        
        <div class="evidence-links">
            <a href="evidence/unit-1-initial-post.jpg" class="evidence-btn">Initial Post</a>
            <a href="evidence/unit2-peer-response.jpg" class="evidence-btn">Peer Responses</a>
            <a href="evidence/unit3-summary-post.jpg" class="evidence-btn">Summary Post</a>
        </div>
    </div>
</div>

<!-- Unit 2 -->
<div class="unit-section">
    <h2>üìä Unit 2: Exploratory Data Analysis</h2>
    <div class="unit-content">
        <h3>Peer Analysis Assignment: Applying EDA Principles to System Failure Cases</h3>
        
        <div class="topic-box">
            <p class="topic-label">Assignment Focus:</p>
            <p>Application of exploratory data analysis techniques to peer-submitted case studies of IT system failures</p>
        </div>
        
        <div class="response-section">
            <h4>Response to Saeed's British Airways Analysis</h4>
            <div class="highlight-box">
                <p>"Infrastructure Resilience: The primary failure stemmed from inadequate power supply redundancy. British Airways should have implemented multiple backup power systems with automatic failover capabilities, including uninterruptible power supplies (UPS) and geographically distributed data centers."</p>
            </div>
            <p class="skills-note">EDA Skills: Systematic feature exploration, anomaly detection, root cause analysis methodology</p>
        </div>
        
        <div class="response-section">
            <h4>Response to Tasnika's Maersk Cybersecurity Analysis</h4>
            <div class="highlight-box">
                <p>"Network Segmentation: Maersk should have implemented robust network segmentation to isolate critical operational technology (OT) systems from information technology (IT) networks. This would have prevented ransomware from spreading across global operations."</p>
            </div>
            <p class="skills-note">EDA Skills: Pattern recognition in attack vectors, data-driven prevention strategy, systematic vulnerability assessment</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Applied structured data analysis approaches to complex system datasets</li>
                <li>Identified key features and anomalies in failure pattern data</li>
                <li>Demonstrated understanding of dataset preparation for predictive analysis</li>
                <li>Conducted visual analysis of interconnected system vulnerabilities</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Professional Issues:</strong> Data privacy, ethical considerations, quality assurance</span>
            <span class="meta-item"><strong>Academic Integration:</strong> Bishop & Bishop (2024) Chapter 3</span>
        </div>
        
        <div class="evidence-links">
            <a href="evidence/unit2-peer-response.jpg" class="evidence-btn">Peer Response Analysis</a>
            <a href="evidence/unit2-peerresponse.jpg" class="evidence-btn">Additional Response</a>
        </div>
    </div>
</div>

<!-- Unit 3 -->
<div class="unit-section">
    <h2>üìà Unit 3: Correlation and Regression</h2>
    <div class="unit-content">
        <h3>Practical Exercise: Jupyter Notebook Analysis of Statistical Relationships</h3>
        
        <div class="topic-box">
            <p class="topic-label">Assignment Focus:</p>
            <p>Hands-on exploration of correlation and regression algorithms using modified parameters to understand data relationship impacts</p>
        </div>
        
        <div class="analysis-section">
            <h4>Covariance and Pearson Correlation Analysis</h4>
            <div class="highlight-box">
                <p>"Demonstrated how increased noise reduces correlation strength from 0.888 to 0.446, while smaller sample sizes affect reliability of correlation estimates (0.894 with n=100)."</p>
            </div>
        </div>
        
        <div class="analysis-section">
            <h4>Linear Regression Experimentation</h4>
            <div class="highlight-box">
                <p>"Compared three scenarios: small dataset (R¬≤=original), large noisy dataset (reduced R¬≤), and perfect linear relationship (R¬≤‚âà1.0), revealing how data quality impacts model performance."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Applied systematic parameter modification to observe algorithm behavior</li>
                <li>Analyzed the impact of sample size and noise on statistical reliability</li>
                <li>Demonstrated understanding of R¬≤ and correlation interpretation</li>
                <li>Evaluated prediction accuracy under different data conditions</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Professional Issues:</strong> Sample size reliability, correlation vs causation ethics</span>
            <span class="meta-item"><strong>Technical Skills:</strong> Jupyter notebook, statistical analysis, data visualization</span>
        </div>
        
        <div class="evidence-links">
            <a href="evidence/unit3-correlation-analysis.png.jpg" class="evidence-btn">Correlation Experiments</a>
            <a href="evidence/unit3-linear-regression-analysis.png" class="evidence-btn">Linear Regression Analysis</a>
        </div>
    </div>
</div>

<!-- Unit 4 -->
<div class="unit-section">
    <h2>ü§ñ Unit 4: Linear Regression with Scikit-Learn</h2>
    <div class="unit-content">
        <h3>Academic Reading Analysis: Supervised Learning Foundations</h3>
        
        <div class="topic-box">
            <p class="topic-label">Assignment Focus:</p>
            <p>Critical analysis of supervised learning approaches through Bishop & Bishop (2024) Chapters 6 & 7, with emphasis on professional and ethical implications</p>
        </div>
        
        <div class="analysis-section">
            <h4>Key Learning from Required Reading</h4>
            <div class="highlight-box">
                <p>"The transition from correlation analysis to supervised learning requires careful consideration of feature selection bias and overfitting risks. Bishop & Bishop's framework emphasizes that supervised learning algorithms can perpetuate historical biases present in training data, creating ethical responsibilities for ML practitioners."</p>
            </div>
        </div>
        
        <div class="analysis-section">
            <h4>Wiki Contribution: Feature Selection Bias</h4>
            <div class="highlight-box">
                <p>"Added comprehensive section on 'Feature Selection Bias in Supervised Learning' explaining how improper feature selection can lead to discriminatory outcomes in ML models, particularly in sensitive applications like hiring algorithms and credit scoring systems."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Analyzed theoretical foundations of supervised learning algorithms</li>
                <li>Identified ethical considerations in feature selection and model training</li>
                <li>Connected academic theory to real-world professional responsibilities</li>
                <li>Contributed knowledge synthesis to collaborative wiki platform</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Professional Issues:</strong> Feature selection bias, algorithmic fairness, responsible AI</span>
            <span class="meta-item"><strong>Academic Integration:</strong> Bishop & Bishop (2024) supervised learning framework</span>
        </div>
        
        <div class="evidence-links">
            <a href="evidence/unit4-reading-analysis.pdf" class="evidence-btn">Reading Analysis</a>
            <a href="evidence/unit4-wiki-contribution.png" class="evidence-btn">Wiki Contribution</a>
        </div>
    </div>
</div>

<!-- Unit 5 -->
<div class="unit-section">
    <h2>üìä Unit 5: Clustering Algorithms - K-Means Visualization</h2>
    <div class="unit-content">
        <h3>Interactive Learning: K-Means Clustering Algorithm</h3>
        
        <div class="topic-box">
            <p class="topic-label">Activity Focus:</p>
            <p>Understanding K-Means clustering through interactive visualization and algorithm analysis</p>
        </div>
        
        <div class="analysis-section">
            <h4>Key Observations from K-Means Animation</h4>
            <div class="highlight-box">
                <p>"The visualization demonstrates how K-Means iteratively assigns points to nearest centroids and updates centroid positions until convergence. Observed how initial centroid placement significantly impacts final clustering results and convergence speed."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes from Visualization</h4>
            <ul class="styled-list">
                <li>Understood the iterative nature of K-Means algorithm</li>
                <li>Observed how clusters form through centroid updates</li>
                <li>Identified the importance of K selection (number of clusters)</li>
                <li>Recognized sensitivity to initial centroid placement</li>
                <li>Analyzed convergence patterns and local minima issues</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>Algorithm Insights</h4>
            <p class="skills-note">Key takeaways: K-Means minimizes within-cluster sum of squares, requires predetermined K value, sensitive to outliers, assumes spherical clusters, and may converge to local optima depending on initialization.</p>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Resource:</strong> Interactive K-Means Visualization by Shabal</span>
            <span class="meta-item"><strong>Algorithm Type:</strong> Unsupervised Learning - Clustering</span>
        </div>
        
        <div class="evidence-links">
            <a href="https://shabal.in/visuals/kmeans/2.html" class="evidence-btn" target="_blank">View K-Means Animation</a>
            <a href="evidence/unit5-clustering-notes.pdf" class="evidence-btn">My Analysis Notes</a>
        </div>
    </div>
</div>

<!-- Unit 5 Part 2 -->
<div class="unit-section">
    <h2>üìê Unit 5: Similarity Measures - Jaccard Coefficient Exercise</h2>
    <div class="unit-content">
        <h3>Practical Exercise: Calculating Jaccard Coefficient for Medical Test Data</h3>
        
        <div class="topic-box">
            <p class="topic-label">Activity Focus:</p>
            <p>Computing similarity measures between patient pathological test results using Jaccard coefficient</p>
        </div>
        
        <div class="analysis-section">
            <h4>Dataset Analysis</h4>
            <p>Working with pathological test results for three individuals (Jack, Mary, Jim) containing:</p>
            <ul>
                <li>Binary symptoms: Fever (Y/N), Cough (N/P)</li>
                <li>Test results: Test-1 through Test-4 with values (P/N/A)</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>Jaccard Coefficient Calculations</h4>
            <div class="highlight-box">
                <p><strong>Jack-Mary:</strong> J = 0.400 (2 matches out of 5 comparisons)<br>
                <strong>Jack-Jim:</strong> J = 0.500 (3 matches out of 6 comparisons)<br>  
                <strong>Jim-Mary:</strong> J = 0.167 (1 match out of 6 comparisons)</p>
            </div>
            <p class="skills-note">Methodology: Jaccard coefficient = (matching values) / (total non-missing comparisons), treating 'A' (Absent) values as missing data excluded from calculations</p>
        </div>
        
        <div class="outcomes-section">
            <h4>Key Insights from Analysis</h4>
            <ul class="styled-list">
                <li>Jack and Jim show highest similarity (0.500) - most similar patients</li>
                <li>Jim and Mary show lowest similarity (0.167) despite both having fever</li>
                <li>Missing data ('A' values) significantly impacts similarity calculations</li>
                <li>Binary and categorical medical data requires careful handling in ML algorithms</li>
                <li>Jaccard coefficient effective for categorical medical datasets</li>
            </ul>
        </div>
        
        <div class="analysis-section">
            <h4>Professional Implications</h4>
            <div class="highlight-box">
                <p>"This exercise demonstrates critical considerations for medical ML applications: handling missing data, choosing appropriate similarity metrics for categorical variables, and understanding how data representation affects patient clustering and diagnosis algorithms."</p>
            </div>
        </div>
        
        <div class="outcomes-section">
            <h4>Learning Outcomes Achieved</h4>
            <ul class="styled-list">
                <li>Articulated legal, social, and ethical issues in medical ML applications</li>
                <li>Understood challenges of different datasets for ML algorithms</li>
                <li>Applied appropriate similarity measures for categorical data</li>
                <li>Recognized importance of missing data handling in healthcare ML</li>
            </ul>
        </div>
        
        <div class="metadata-row">
            <span class="meta-item"><strong>Skills Applied:</strong> Python programming, similarity measures, categorical data analysis</span>
            <span class="meta-item"><strong>Professional Issues:</strong> Medical data privacy, algorithmic fairness in healthcare</span>
        </div>
        
        <div class="evidence-links">
            <a href="https://colab.research.google.com/drive/17UeMg1-uAb1f4Y4WPzxTNNV3ohjobm2v?usp=sharing" class="evidence-btn" target="_blank">View Calculations in Colab</a>
        </div>
    </div>
</div>

<style>
.unit-section {
    background: #f8f9fa;
    border-radius: 12px;
    margin: 40px 0;
    overflow: hidden;
    box-shadow: 0 2px 10px rgba(0,0,0,0.08);
}

.unit-section h2 {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 20px 30px;
    margin: 0;
    font-size: 1.5em;
}

.unit-content {
    padding: 30px;
}

.unit-content h3 {
    color: #2c3e50;
    border-left: 4px solid #667eea;
    padding-left: 15px;
    margin-bottom: 25px;
}

.topic-box {
    background: white;
    padding: 15px;
    border-radius: 8px;
    margin-bottom: 20px;
    border: 1px solid #e0e0e0;
}

.topic-label {
    font-weight: 600;
    color: #667eea;
    margin-bottom: 5px;
}

.highlight-box {
    background: #fff3cd;
    border-left: 4px solid #ffc107;
    padding: 20px;
    margin: 20px 0;
    border-radius: 4px;
    font-style: italic;
}

.response-section, .analysis-section {
    margin: 30px 0;
}

.response-section h4, .analysis-section h4 {
    color: #495057;
    margin-bottom: 15px;
}

.outcomes-section {
    background: white;
    padding: 20px;
    border-radius: 8px;
    margin: 25px 0;
}

.outcomes-section h4 {
    color: #28a745;
    margin-bottom: 15px;
}

.styled-list {
    list-style: none;
    padding-left: 0;
}

.styled-list li {
    padding: 8px 0;
    padding-left: 30px;
    position: relative;
}

.styled-list li:before {
    content: "‚úì";
    position: absolute;
    left: 0;
    color: #28a745;
    font-weight: bold;
}

.skills-note {
    color: #6c757d;
    font-style: italic;
    margin-top: 10px;
}

.metadata-row {
    display: flex;
    flex-wrap: wrap;
    gap: 30px;
    margin: 25px 0;
    padding: 15px;
    background: #f1f3f5;
    border-radius: 8px;
}

.meta-item {
    flex: 1;
    min-width: 250px;
}

.evidence-links {
    margin-top: 25px;
    padding-top: 20px;
    border-top: 2px solid #e9ecef;
}

.evidence-btn {
    display: inline-block;
    padding: 10px 20px;
    background: #667eea;
    color: white !important;
    border-radius: 6px;
    text-decoration: none !important;
    margin-right: 10px;
    margin-bottom: 10px;
    transition: all 0.3s ease;
}

.evidence-btn:hover {
    background: #5a67d8;
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
}
</style>
